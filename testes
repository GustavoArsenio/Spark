cd ~/spark-2.4.2-bin-hadoop2.7/
cd python/
python

import pyspark
from pyspark.sql.functions import length
from pyspark.ml.feature import (Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer)
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.classification import NaiveBayes
from pyspark.ml import Pipeline
from pyspark.ml.evaluation import MulticlassClassificationEvaluator

spark = pyspark.sql.SparkSession.builder.appName('Processamento_Linguagem_natural').getOrCreate()
data = spark.read.csv('smsspamcollection/SMSSpamCollection',inferSchema=True,sep='\t')
data.show()
data = data.withColumnRenamed('_c0','class').withColumnRenamed('_c1','text')
data
DataFrame[class: string, text: string]
data = data.withColumn('length',length(data['text']))
data
DataFrame[class: string, text: string, length: int]
data.show()
data.groupBy('class').mean().show()
tokenizer = Tokenizer(inputCol='text',outputCol='token_text')
stop_remove = StopWordsRemover(inputCol='token_text',outputCol='stop_token')
count_vec = CountVectorizer(inputCol='stop_token',outputCol='c_vec')
idf = IDF(inputCol='c_vec',outputCol='tf_idf')
ham_spam_to_numeric = StringIndexer(inputCol='class',outputCol='label')
clean_up = VectorAssembler(inputCols=['tf_idf','length'],outputCol='features')
nb = NaiveBayes()
data_prep_pipe = Pipeline(stages=[ham_spam_to_numeric,tokenizer,stop_remove,count_vec,idf,clean_up])
cleaner = data_prep_pipe.fit(data)
clean_data = cleaner.transform(data)
clean_data = clean_data.select('label','features')
clean_data.show()
train,test = clean_data.randomSplit([0.7,0.3])
spam_detector= nb.fit(train)
data.printSchema()
test_results = spam_detector.transform(test)
test_results.show()
acc_eval =  MulticlassClassificationEvaluator()
acc = acc_eval.evaluate(test_results)
acc